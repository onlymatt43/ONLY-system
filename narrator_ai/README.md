# üß† Narrator AI - Bloc #2

Service d'analyse et g√©n√©ration de m√©tadonn√©es pour les vid√©os.

## üéØ R√¥le

- Analyse les fichiers vid√©o (dur√©e, r√©solution, codec, etc.)
- G√©n√®re titre, description et tags
- Support multiple IA : local (fallback), Ollama, OpenAI, Anthropic
- Ind√©pendant et modulaire

## üöÄ D√©marrage

```bash
cd narrator_ai
pip install -r requirements.txt

# Installer ffprobe (si pas d√©j√† install√©)
brew install ffmpeg  # macOS

cp .env.example .env
# √âditer .env avec tes param√®tres
python3 narrator_ai.py
```

Le service d√©marre sur **http://localhost:5056**

## ‚öôÔ∏è Configuration (.env)

```env
PORT=5056
AI_PROVIDER=local        # local|ollama|openai|anthropic
LOCAL_MODEL=llama2       # si ollama
OPENAI_API_KEY=          # si openai
```

## üîó API

### GET /
Status du service

### POST /describe
Analyse une vid√©o et g√©n√®re les m√©tadonn√©es

```bash
curl -X POST http://localhost:5056/describe \
  -H "Content-Type: application/json" \
  -d '{"file":"/path/to/video.mp4"}'
```

**R√©ponse:**

```json
{
  "title": "Shadows in Motion",
  "description": "Une exploration po√©tique de la lumi√®re et du mouvement. Subtil, hypnotique, contemplatif.",
  "tags": ["art nude", "slow motion", "black and white", "fine art"],
  "category": "Art",
  "file": "/path/to/video.mp4",
  "video_info": {
    "duration": 180.5,
    "width": 1920,
    "height": 1080,
    "codec": "h264",
    "fps": 24
  }
}
```

## ü§ñ Modes IA

### Local (fallback)
- Aucune d√©pendance externe
- G√©n√©ration basique bas√©e sur le nom de fichier
- Toujours disponible

### Ollama
- IA locale via Ollama
- Gratuit, priv√©, pas de limite
- N√©cessite Ollama install√©: `ollama run llama2`

### OpenAI
- GPT-4 pour descriptions riches
- Co√ªt par requ√™te
- N√©cessite cl√© API

## üîß Ind√©pendance

- Fonctionne hors ligne (mode local)
- Pas de d√©pendance cloud obligatoire
- Peut √™tre remplac√© par un autre syst√®me d'IA
- Communication HTTP uniquement
